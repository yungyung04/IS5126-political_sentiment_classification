{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (1.68.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ekabu\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\ekabu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\ekabu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\ekabu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\ekabu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\ekabu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\ekabu\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ekabu\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "\n",
    "openai.api_key = \"REPLACE WITH OPEN AI API KEY\" #API key\n",
    "chosen_model = \"gpt-4o\" #Choose your GPT model here\n",
    "\n",
    "test_api_key = False #True\n",
    "if test_api_key:\n",
    "    try:\n",
    "        openai.models.list()  # Test API call\n",
    "        print(\"API key is valid.\")\n",
    "    except openai.error.AuthenticationError:\n",
    "        print(\"Invalid API key.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  Forensic Audit: \"We conclude that the Dominion...\n",
      "1  Biden and The Squad's Tlaib stage heated confr...\n",
      "2  President-elect Biden is projected to win Penn...\n",
      "3  Not even an issue of politics it's wrong this ...\n",
      "4  Young man wearing MAGA hat attacked at school ...\n",
      "Shape of df: (14048, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"subreddit_dataset_full_unlabeled.csv\", on_bad_lines=\"skip\")\n",
    "print(df.head())\n",
    "print(f\"Shape of df: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_label_texts(texts):\n",
    "    \"\"\"Classifies multiple texts in a single API call.\"\"\"\n",
    "    prompt = f\"\"\"Classify the text into one of the following categories: Democratic, Republican, or NA.\n",
    "    -Democratic: Supports Democratic party, its members/policies, or show negative sentiment of the opposition party/member/policies.\n",
    "    -Republican: Supports Republican party, its members/policies, or show negative sentiment of the opposition party/member/policies.\n",
    "    -NA: Neutral or unrelated.\n",
    "\n",
    "    Provide labels in this format: \n",
    "    1. <category>\n",
    "    2. <category>\n",
    "    3. <category>\n",
    "    ...\n",
    "    \n",
    "    Texts to classify:\n",
    "    \"\"\" + \"\\n\".join([f\"{i+1}. {text}\" for i, text in enumerate(texts)])\n",
    "\n",
    "    for attempt in range(3):  # Retry logic\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=chosen_model,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful text classifier.\"},\n",
    "                          {\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            \n",
    "            labels = response.choices[0].message.content.strip().split(\"\\n\")\n",
    "            return [label.split(\". \")[-1] for label in labels]  # Extract labels\n",
    "        except openai.RateLimitError:\n",
    "            print(\"Rate limit reached. Waiting before retrying...\")\n",
    "            time.sleep(10)\n",
    "        except openai.APITimeoutError:\n",
    "            print(\"Request timed out. Retrying...\")\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return [\"Error\"] * len(texts)\n",
    "\n",
    "    return [\"Error\"] * len(texts)  # If it fails after retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in batches\n",
    "batch_size = 10\n",
    "labeled_data = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df[\"Text\"].iloc[i:i+batch_size].tolist()\n",
    "    labels = batch_label_texts(batch)\n",
    "    \n",
    "    for text, label in zip(batch, labels):\n",
    "        labeled_data.append({\"Text\": text, \"Label\": label})\n",
    "    \n",
    "    time.sleep(1)  # Reduce rate limit issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling completed. Saved to .csv.\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "df_labeled = pd.DataFrame(labeled_data)\n",
    "df_labeled.to_csv(\"subreddit_dataset_full_labeled_gpt4o.csv\", index=False)\n",
    "\n",
    "print(\"Labeling completed. Saved to .csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
